{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of our deep learning model, a Transformer, is to analyze game reviews and classify the sentiments associated with these reviews.  \n",
    "To train our model, we will use the \"Steam Reviews\" dataset, available at: https://www.kaggle.com/datasets/andrewmvd/steam-reviews.  \n",
    "This dataset includes, among other features, 6.4 million English reviews from the Steam platform.  \n",
    "Each review in the dataset is labeled with its sentiment: 1 for positive and -1 for negative.  \n",
    "The objective of our model is to take a game review as input and predict whether the sentiment is positive or negative.  \n",
    "To implement the model, we will use the Keras API provided by TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1/ Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing the Transformer and training it with our data, it is necessary to :  \n",
    "- Load the dataset (store in .csv format in the \"datasets\" folder)\n",
    "- Seperate this dataset in train data, validation data and test data\n",
    "- Transform these initial text data into token sequences\n",
    "- Pad these sequences to ensure they have the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset importing and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "dataset = pd.read_csv(\"datasets/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app_id        app_name                                        review_text  \\\n",
      "0      10  Counter-Strike                                    Ruined my life.   \n",
      "1      10  Counter-Strike  This will be more of a ''my experience with th...   \n",
      "2      10  Counter-Strike                      This game saved my virginity.   \n",
      "3      10  Counter-Strike  • Do you like original games? • Do you like ga...   \n",
      "4      10  Counter-Strike           Easy to learn, hard to master.             \n",
      "\n",
      "   review_score  review_votes  \n",
      "0             1             0  \n",
      "1             1             1  \n",
      "2             1             0  \n",
      "3             1             0  \n",
      "4             1             1  \n"
     ]
    }
   ],
   "source": [
    "# Data overview\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews : 6417106\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of reviews :\", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this dataset includes 6.4 million reviews, this number is too high, so it is necessary to keep only a portion of these reviews by selecting them randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of the sample size\n",
    "sample_size = 100000\n",
    "\n",
    "# Randomly select review indices\n",
    "index_reviews_kept = random.sample(range(len(dataset)), 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will keep the data that interest us: review content ('review_text') and their associated sentiment ('review_score')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data by converting it into a numpy array and setting the review format to string\n",
    "X = np.array(dataset.iloc[index_reviews_kept].review_text, dtype = \"str\")\n",
    "y = np.array(dataset.iloc[index_reviews_kept].review_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Terraria is a fun game to play with your friends and the updates as of late expanded the already great game even further, sadly there is no real motivation to play this game alone, it's, at least in my opinion, only fun when you play it with others.\n",
      "1 Perfect addition to the series, looks fantastic, great humour, challenging ( but not overly so ) puzzels and some friendly familler faces.\n",
      "1 Goodbye life.  Everything I expected and more, will be nice to see where this game goes.  Chalked full of content, very accessible to those that are new to grand strategy games and 4X alike.   MP is seamless as well, played for hours straight with no problems.  10/10\n"
     ]
    }
   ],
   "source": [
    "for i in range(3) :\n",
    "    print(y[i], X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

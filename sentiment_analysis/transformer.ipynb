{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of our deep learning model, a Transformer, is to analyze game reviews and classify the sentiments associated with these reviews.  \n",
    "To train our model, we will use the \"Steam Reviews\" dataset, available at: https://www.kaggle.com/datasets/andrewmvd/steam-reviews.  \n",
    "This dataset includes, among other features, 6.4 million English reviews from the Steam platform.  \n",
    "Each review in the dataset is labeled with its sentiment: 1 for positive and -1 for negative.  \n",
    "The objective of our model is to take a game review as input and predict whether the sentiment is positive or negative.  \n",
    "To implement the model, we will use the Keras API provided by TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1/ Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing the Transformer and training it with our data, it is necessary to :  \n",
    "- Load the dataset (store in .csv format in the \"datasets\" folder)\n",
    "- Seperate this dataset in train data, validation data and test data\n",
    "- Transform these initial text data into token sequences\n",
    "- Pad these sequences to ensure they have the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset importing and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "dataset = pd.read_csv(\"datasets/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app_id        app_name                                        review_text  \\\n",
      "0      10  Counter-Strike                                    Ruined my life.   \n",
      "1      10  Counter-Strike  This will be more of a ''my experience with th...   \n",
      "2      10  Counter-Strike                      This game saved my virginity.   \n",
      "3      10  Counter-Strike  • Do you like original games? • Do you like ga...   \n",
      "4      10  Counter-Strike           Easy to learn, hard to master.             \n",
      "\n",
      "   review_score  review_votes  \n",
      "0             1             0  \n",
      "1             1             1  \n",
      "2             1             0  \n",
      "3             1             0  \n",
      "4             1             1  \n"
     ]
    }
   ],
   "source": [
    "# Data overview\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews : 6417106\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of reviews :\", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this dataset includes 6.4 million reviews, this number is too high, so it is necessary to keep only a portion of these reviews by selecting them randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of the sample size\n",
    "sample_size = 100000\n",
    "\n",
    "# Randomly select review indices\n",
    "index_reviews_kept = random.sample(range(len(dataset)), sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will keep the data that interest us: review content ('review_text') and their associated sentiment ('review_score')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data by converting it into a numpy array and setting the review format to string\n",
    "X = np.array(dataset.iloc[index_reviews_kept].review_text, dtype = \"str\")\n",
    "y = np.array(dataset.iloc[index_reviews_kept].review_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  Early Access Review\n",
      "1 continues great gameplay from the first game\n",
      "1 What can I say about this timeless masterpiece?!?!'? Some of the best action around mixed with a deep story and amazing story telling make this an exhilirating and engaging experience like never before. It's 2013, and I'm still impressed.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3) :\n",
    "    print(y[i], X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the sentiment value for negative sentiment to 0\n",
    "y[y == -1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we will split the data into training, validation, and test sets to train the transformer model.  \n",
    "The training set will contain 60% of the initial data, while the validation and test sets will each contain 20% of the initial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data using the train_test_split function from scikit-learn\n",
    "X_train, X_test_full, y_train, y_test_full = train_test_split(X, y, train_size = 0.6, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = X_test_full[:int(len(X_test_full)/2)], y_test_full[:int(len(X_test_full)/2)]\n",
    "X_test, y_test = X_test_full[int(len(X_test_full)/2):], y_test_full[int(len(X_test_full)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (20000,) (20000,)\n",
      "(60000,) (20000,) (20000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenisation of text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step consists of transforming the review's words into tokens in order to make this data readable by the AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of words for the token dictionary\n",
    "num_words = 4000\n",
    "\n",
    "# Instantiate the Tokeniser and fit it on the training data\n",
    "tokenizer = Tokenizer(num_words = num_words, oov_token = \"UNK\")\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different words in the data : 66498\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of different words in the data : %d\" % len(tokenizer.word_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of occurrences for OOV words : 50\n"
     ]
    }
   ],
   "source": [
    "max_occurences_oov_words = tokenizer.word_counts[tokenizer.index_word[num_words]]\n",
    "print(\"Maximum number of occurrences for OOV words :\" , max_occurences_oov_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert sentences composed of words into sequences of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[791, 1503, 5, 105, 1509, 5, 91, 12, 6, 132, 64, 21, 91, 2, 6, 23, 10, 307, 20, 2, 238, 87, 1, 1851, 4, 321, 109, 8, 94, 1924, 1, 3, 1026, 1, 22, 75, 73, 5, 54, 9, 21, 107, 551, 703, 117, 23, 10, 68, 20, 2, 586, 6, 81, 39, 1, 97, 1463, 2, 1309, 290, 8, 376, 665, 1141, 1, 43, 2, 376, 665, 948, 20, 245, 3618, 54, 1635, 120, 285, 139, 8, 988, 70, 2, 6, 16, 12, 6, 9, 21, 164, 67, 7, 905, 13, 4, 36, 3, 127, 98, 340, 54, 80, 1, 2, 2993, 3, 2550, 781, 12, 6, 1022, 2, 293, 9, 1944, 47, 19, 1510, 707, 102, 1510, 707, 3, 2, 151, 9, 864, 73, 9, 4, 3088, 1, 8, 1, 7, 20, 1, 108, 93, 8, 12, 6, 3, 7, 79, 131, 7, 20, 4, 186, 98, 5, 112, 13, 196, 740, 10, 19, 1636, 1312, 72, 4, 1304, 14, 463, 5, 25, 2861, 11, 9, 494, 10, 26, 501, 18, 5, 251, 740, 130, 10, 26, 972, 1188, 73, 9, 2133, 5, 25, 376, 665, 302, 1323, 1, 10, 656, 85, 743, 369, 77, 2, 1, 1090, 72, 370, 12, 1323, 2, 6, 9, 21, 1027, 11, 9, 50, 1, 1, 23, 120, 6, 63, 1013, 12, 3718, 11, 52, 708, 50, 1, 55, 8, 42, 1022, 2, 674, 13, 376, 665, 1141, 1, 9, 4, 1, 7, 92, 2551, 13, 1, 3, 1, 2, 2518, 2, 201, 13, 85, 743, 9, 83, 119, 7, 248, 126, 84, 11, 985, 10, 86, 2, 6, 1, 10, 234, 25, 1042, 533, 1436, 16, 23, 10, 19, 5, 91, 12, 6, 10, 52, 265, 28, 448, 176, 3, 1, 41, 2, 305, 1981, 178, 28, 1232, 47, 19, 66, 456, 14, 52, 1, 10, 5, 20, 4, 1, 3, 376, 436, 24, 2, 283, 376, 665, 6, 1022, 2, 232, 958, 232, 958, 232, 47, 9, 4, 522, 8, 232, 5, 506, 3232, 1, 1, 1423, 5, 1750, 3, 1, 17, 11, 9, 13, 28, 1134, 5, 2331, 3, 381, 1, 2, 1887, 12, 177, 213, 9, 2, 78, 8, 67, 1, 26, 1516, 5, 2406, 82, 12, 6, 826, 2171, 8, 2420, 3, 826, 42, 1022, 67, 2117, 12, 6, 56, 30, 1, 1997, 31, 2, 238, 30, 637, 2, 293, 31, 1, 120, 740, 10, 1576, 9, 4, 305, 253, 2464, 3546, 171, 1, 1666, 9, 72, 173, 30, 412, 740, 22, 75, 22, 61, 69, 10, 3352, 86, 11, 40, 2, 293, 26, 25, 575, 13, 396, 551, 93, 32, 543, 16, 11, 576, 2552, 18, 2, 2344, 121, 1277, 17, 2, 1, 48, 27, 7, 1414, 67, 7, 809, 5, 64, 2967, 2, 204, 9, 1049, 1, 835, 5, 2, 85, 1783, 48, 11, 985, 57, 743, 17, 1, 3, 1, 1475, 14, 708, 365, 10, 1774, 15, 28, 226, 35, 1, 695, 5, 25, 13, 14, 1167, 740, 3583, 2, 204, 1, 5, 90, 362, 376, 16, 1442, 7, 621, 1216, 21, 50, 1, 424, 5, 25, 2, 284, 2235, 41, 2, 442, 9, 4, 2553, 5, 1142, 5, 730, 1, 35, 330, 220, 19, 156, 5, 25, 13, 97, 369, 77, 376, 665, 11, 31, 36, 16, 21, 22, 2789, 69, 11, 507, 5, 1, 2, 3443, 8, 1, 9, 2, 2376, 8, 220, 27, 99, 8, 2, 1, 63, 25, 312, 191, 434, 177, 65, 2, 68, 1056, 14, 19, 1537, 76, 19, 968, 2773, 1815, 1, 1, 1, 1538, 3814, 3, 1, 3814, 2, 474, 20, 4, 122, 92, 16, 11, 9, 4, 1443, 2057, 5, 939, 2, 3815, 1, 192, 10, 20, 5, 346, 15, 228, 5, 1576, 28, 1009, 7, 533, 3619, 386, 13, 214, 1, 1067, 2, 283, 1, 13, 1, 1, 1, 7, 1, 1, 164, 11, 31, 255, 15, 2, 1538, 255, 15, 3584, 35, 1, 3233, 5, 2, 1315, 16, 17, 1, 222, 19, 1424, 5, 50, 436, 8, 255, 15, 2553, 295, 8, 423, 73, 155, 875, 554, 5, 67, 1, 10, 1576, 730, 2, 1048, 3, 148, 19, 527, 835, 5, 1, 665, 3, 376, 665, 2, 600, 1783, 48, 20, 1, 1, 5, 196, 3, 120, 172, 10, 1425, 14, 179, 10, 125, 1, 1, 1, 3, 1, 10, 101, 5, 359, 89, 24, 106, 349, 63, 16, 219, 52, 359, 89, 65, 577, 96, 71, 10, 101, 5, 1, 1, 3477, 120, 172, 10, 1425, 1, 59, 4, 878, 1, 442, 14, 52, 989, 5, 28, 414, 1272, 1572, 10, 1, 1, 64, 7, 153, 126, 40, 22, 15, 376, 665, 1141, 2, 148, 19, 21, 1763, 13, 727, 314, 10, 1982, 5, 89, 130, 58, 1031, 70, 143, 376, 531, 16, 11, 190, 21, 66, 2106, 5, 2, 376, 436, 8, 2, 600, 48, 539, 206, 184, 57, 2, 99, 1, 3, 1763, 807, 8, 2, 376, 665, 948, 3, 90, 11, 13, 5, 4, 246, 1, 345, 6, 73, 9, 539, 21, 159, 41, 32, 17, 1, 58, 511, 5, 819, 142, 2, 1048, 15, 196, 8, 2, 707, 16, 13, 2, 194, 11, 31, 4, 1, 5, 2, 653, 15, 520, 571, 15, 1916, 2, 1, 1, 1, 1048, 9, 4, 1, 438, 567, 1, 567, 767, 450, 5, 218, 24, 4, 1, 1272, 3, 31, 1, 5, 11, 3, 3033, 311, 60, 2, 194, 1936, 83, 13, 2, 600, 48, 10, 20, 1, 5, 2, 320, 707, 72, 751, 143, 1233, 35, 69, 10, 1031, 5, 3142, 730, 2, 707, 13, 376, 665, 1141, 19, 64, 7, 20, 5, 126, 527, 23, 10, 19, 4, 2889, 8, 376, 665, 3, 1, 665, 10, 145, 67, 7, 202, 1121, 70, 263, 120, 469, 10, 1425, 9, 1, 3, 59, 2, 158, 1, 73, 9, 1, 72, 457, 965, 150, 13, 4, 1, 11, 2214, 30, 878, 13, 96, 239, 2, 707, 19, 7, 64, 21, 145, 67, 2, 445, 56, 56, 1468, 165, 745, 16, 2, 68, 166, 14, 58, 2407, 420, 12, 6, 31, 5, 90, 11, 22, 345, 22, 569, 3, 5, 64, 12, 9, 72, 1, 10, 504, 40, 77, 87, 117, 40, 707, 35, 5, 1876, 1510, 608, 5, 90, 28, 226, 1, 482, 4, 3665, 2862, 8, 707, 3, 1510, 608, 5, 1, 10, 12, 9, 21, 345, 827, 2, 68, 166, 12, 6, 52, 1531, 10, 5, 25, 9, 2, 99, 2890, 349, 110, 3583, 17, 2, 1309, 290, 8, 1, 1, 1952, 183, 316, 24, 4, 321, 157, 642, 274, 183, 1, 303, 1, 69, 10, 1750, 1423, 3, 9, 183, 4, 496, 97, 7, 31, 27, 695, 69, 58, 193, 12, 539, 274, 31, 4, 375, 1150, 17, 2, 586, 6, 8, 1, 1141, 3968, 1, 7, 46, 64, 21, 20, 256, 398, 5, 126, 16, 23, 10, 19, 1156, 4, 6, 14, 9, 103, 35, 60, 5, 2361, 17, 1, 665, 3, 376, 665, 12, 9, 21, 2, 6, 66, 141, 7, 20, 76, 1, 665, 3, 376, 665, 1877, 93, 7, 248, 126, 1044, 14, 12, 6, 1396, 2, 1, 8, 67, 146, 2, 1783, 48, 4, 299, 82, 171, 7, 689, 17, 2, 2026, 2, 283, 376, 665, 2945, 17, 1, 5, 1, 56, 1, 969, 31, 5, 90, 759, 1678, 22, 1, 22, 569, 72, 1517, 4, 6, 130, 1, 31, 5, 1082, 22, 108, 233, 41, 10, 22, 58, 26, 16, 13, 2689, 58, 2172, 2, 99, 1, 1, 5, 143, 6, 1763, 148, 3, 143, 2317, 1048, 849, 1, 7, 401, 10, 327, 30, 43, 14, 7, 931, 470, 125, 167, 5, 2201, 54, 27, 7, 26, 1498, 13, 40, 988, 70, 30, 1, 66, 141, 30, 43, 9, 1693, 730, 7, 63, 79, 104, 12, 6, 27, 71, 42, 539, 7, 63, 162, 376, 665, 2070, 5, 338, 944, 4, 1637], [1, 12, 9, 4, 246, 43, 3, 21, 4, 80, 1, 43, 24, 32, 30, 85, 458, 23, 10, 101, 4, 103, 246, 43, 81, 470, 528, 103, 458, 81, 1096], [46, 728, 3292, 96, 42, 11, 9, 23, 10, 33, 12, 80, 178, 34, 686, 87, 235, 39, 5, 145, 2, 142, 61]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sequences[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding the sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it is necessary to pad these sequences : since they don't have all the same lengths (the sentences don't all contain the same number of words), they can't be used by the model.  \n",
    "We will pad these sequences by truncading those that exceed a predifined maximum length (= \"maxlen\"), and filling the shorter sequences with zeros until they reach maxlen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose a coherent maximum sequence length, we will analyze the length of our sequence using Pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the first 3 sequences:\n",
      "0    1309\n",
      "1      31\n",
      "2      23\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a Pandas Series that contains the sequence lengths as values\n",
    "sequence_lengths = pd.Series([len(review) for review in X_train_sequences])\n",
    "print(\"Length of the first 3 sequences:\", sequence_lengths.head(3), sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    60000.000000\n",
      "mean        56.435850\n",
      "std        109.447465\n",
      "min          0.000000\n",
      "25%          6.000000\n",
      "50%         20.000000\n",
      "75%         58.000000\n",
      "max       1722.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Statistical description of sequence lengths\n",
    "print(sequence_lengths.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391.0\n"
     ]
    }
   ],
   "source": [
    "print(sequence_lengths.quantile(q = 0.98))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram of sequence lengths :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Histogram of sequence lengths :\")\n",
    "sequence_lengths.hist(range = (0, 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that if we choose to keep the first 400 elements of all sequences, we will retain the full content of more than 98% of them, which seems to be reasonable.  \n",
    "So now, we will pad these sequences by setting the \"maxlen\" parameter to 400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 400\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen = maxlen)\n",
    "X_val_padded = pad_sequences(X_val_sequences, maxlen = maxlen)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class of X_train_sequences : <class 'list'>\n",
      "Class of X_train_padded <class 'numpy.ndarray'>\n",
      "Dimension of X_train_padded : (60000, 400)\n"
     ]
    }
   ],
   "source": [
    "print(\"Class of X_train_sequences :\", type(X_train_sequences))\n",
    "print(\"Class of X_train_padded\", type(X_train_padded))\n",
    "print(\"Dimension of X_train_padded :\", np.shape(X_train_padded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our data is now contained in Numpy arrays, where each row of these arrays corresponds to a token sequence, while each column corresponds to a token.  \n",
    "As a result, we have a trainable dataset for the AI model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2/ Create the \"Transformer\" AI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In this part, we will implement the structure of our Transformer, that will be used to classify the sentiment of the reviews.  \n",
    "To do this, we will use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
